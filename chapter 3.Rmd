---
title: "Chapter 3"
output: html_document
---


# Chapter 3: Logistic regression analysis

## we started with data wrangling, and preprocessed the data for down stream analysis. 

### Link to original data:  

<https://archive.ics.uci.edu/ml/datasets/Student+Performance>

<<<<<<< HEAD
### Link to Data Wrnagling in R script:  
<https://github.com/ferozef/IODS-project/blob/master/Data_folder/create_alc.R>
### Original data and preprocessing  
=======
###Link to Data Wrnagling in R script:  
<https://github.com/ferozef/IODS-project/blob/master/Data_folder/create_alc.R>
###Original data and preprocessing  
>>>>>>> ac3bb1c19ca02f61c4fc264a74384610b6aa97e4

Original data sets consist of students from Math (1) and Portuguese language (2) classes who answered to several questions to assess their economical, family and activity status, and variables related to studying and alcoholc consumption. In data pre-processing, individual students were identified based on combination of 13 variables and only students present in both datasets were selected.  

Alcohol use was evaluated numerically, separately for weekdays and weekends. To quantify overall consumption, average for these 2 variables was calculated into column `alc_use`. To group students into high and low alcohol use, threshold of 2 was applied to identify students with high alcohol use in a column `high_use`.
<<<<<<< HEAD
setwd("~/R/IODS-project")
### This datase has 35 variables and 382 observation. Out this 35 variables 17 are factors variables, 3 integer , 1 logcial and 14 numeric.

```{r}
alc <- read.csv("C:/Users/Javed/Documents/IODS-project/Data_folder/alc.csv")

setwd("C:/Users/Javed/Documents/IODS-project")
### This datase has 35 variables and 382 observation. Out this 35 variables 17 are factors variables, 3 integer , 1 logcial and 14 numeric.

```{r}
alc <- read.csv("C:/Users/Javed/Documents/IODS-project/Data_folder/alc.csv")

head(alc)
dim(alc)
str(alc)
```



## hypothesis prior to analysis

We selected Four interesting variables that could predict high alcohol consumption:

1.  absences
    + High alcohol use could lead to more absences
2.  failures
    + Perhaps problematic alcohol use could be more likely due to failures
3.  sex
    + Male gender could predispose to high alcohol use
4.  absences
    + Could lead to higher alcohol use (being problematic use or not) because students usaul being absences could be involved alcohol.
    
    
```{r}
my_model_1 <- c('absences', 'failures', 'sex', 'absences', 'high_use')
```    



## Graphical data exploration & Summary statistics



##question number 3
##to create models
my_model_1 <- glm(high_use ~ failures + absences+ sex+romantic, data = alc, family = "binomial")



```{r}
summary(my_model_1)
```

##we ran a binary logistic regression model with high alocohol usage as the dependent variable
##four variable of interest were taken as predictors of the model(failures,absences, sexM,romantic)
##out the four predicted variables, 3 variables failures,absences, and sexM showed a positive significant association with a outcome variable.


## predict() the probability of high_use
probabilities <- predict(my_model_1, type = "response")

##add the predicted probabilities to 'alc'
alc <- mutate(alc, probability = probabilities)

##use the probabilities to make a prediction of high_use
alc <- mutate(alc, prediction = probability >0.5 )

##see the last ten original classes, predicted probabilities, and class predictions
select(alc, failures, absences, sex, high_use, probability, prediction) %>% tail(10)

##tabulate the target variable versus the predictions
table (high_use = alc$high_use, prediction = alc$prediction)

##prediction
##high_use FALSE TRUE
##FALSE   256   12
##TRUE     84   30

##The table above shows that the true negatives in our model regarding high_use
##in a significantly high proportion(256/268*100=95.52%)this denote a very high specificity and 
##lose chance of type two error in the dataset regarding high alocohol usage.


```{r, echo=FALSE}
library(dplyr); library(ggplot2)

# initialize a plot of 'high_use' versus 'probability' in 'alc'
g <- ggplot(alc, aes(x = probability, y = high_use , col = prediction ) )




```



<<<<<<< HEAD
### tabulate the target variable versus the predictions
=======
## tabulate the target variable versus the predictions
<<<<<<< HEAD
>>>>>>> ac3bb1c19ca02f61c4fc264a74384610b6aa97e4
=======
>>>>>>> ac3bb1c19ca02f61c4fc264a74384610b6aa97e4

table(high_use = alc$high_use, prediction = alc$prediction)%>%prop.table()%>%addmargins()

##prediction
##high_use      FALSE       TRUE        Sum
##FALSE    0.67015707 0.03141361 0.70157068
##TRUE     0.21989529 0.07853403 0.29842932
##Sum      0.89005236 0.10994764 1.00000000




```{r}
## produce summary statistics by group
alc %>% group_by(sex) %>% summarise(count = n())

alc %>% group_by(sex) %>% summarise(count = n(), mean_grade = mean(G3))

alc %>% group_by(sex, high_use) %>% summarise(count = n(), mean_grade = mean(G3))

## initialize a plot of high_use and G3
g1 <- ggplot(alc, aes(x = high_use, y = G3, col = sex))

## define the plot as a boxplot and draw it
g1 + geom_boxplot() + ylab("grade")

## initialise a plot of high_use and absences

g1 <- ggplot(alc, aes(x = high_use, y = absences, col = sex))
## define the plot as a boxplot and draw it

g1 + geom_boxplot() + ylab("grade")+ ggtitle("Student absences by alcohol consumption and sex")

g1+geom_point()
##the box plot shows that the males of significantly lower  greades have a higher prevalence in terms of high alocohol usage compared to female.
##Regarding non usage of alocohol, the difference in between the gender is apparently trivial. 
```


```{r}
##question number 5
## find the model with glm()
my_model_1 <- glm(high_use ~ failures + absences + sex+ romantic, data = alc, family = "binomial")

## compute odds ratios (OR)
OR <- coef(my_model_1) %>% exp

## compute confidence intervals (CI)
CI <- confint(my_model_1) %>% exp

## print out the odds ratios with their confidence intervals
cbind(OR, CI)

##odd ratio and confidence ratio of significant predictors in previous models
##                     OR      2.5 %    97.5 %
##  (Intercept) 0.1606994 0.09898897 0.2519302
##  failures    1.5740272 1.08568128 2.3050629
##  absences    1.0994355 1.05336109 1.1527402
##  sexM        2.5301750 1.58131504 4.1005152
##  romanticyes 0.7799690 0.46257612 1.2936660

##the variable of high failures had 1.56 times higher odds of high alocohol usage(95% CI= 1.08 to 2.3)
##the variable of absences  had 1.09 times higher odds of high alocohol usage(95% CI= 1.05 to 1.15)
##the variable of sex had 2.53 times higher odds of high alocohol usage(95% CI= 1.58 to 4.1)


```


### Summary statistics by group
Question 6. 2x2 cross tabulation of predictions versus the actual values 
```{r}
alc%>% group_by(sex) %>% summarise(count = n(), mean_absences = mean(absences), mean_failures = mean(failures))

```
    
    
    
### Performing 10-fold cross-validation on my_model_1
```{r}
## define a loss function (average prediction error)
loss_func <- function(class, prob) {
  n_wrong <- abs(class - prob) > 0.5
  mean(n_wrong)
}

## compute the average number of wrong predictions in the (training) data

loss_func(class = alc$high_use, prob = alc$probability)
## K-fold cross-validation
library(boot)
cv <- cv.glm(data = alc, cost = loss_func, glmfit = my_model_1, K = 10)

## average number of wrong predictions in the cross validation

cv$delta[1]

```
##Average number of wrong predicition in cross validation 0,2565, this shows that our model has realtive small error rate as shown by number of wrong predicition through cross-valiadation.
